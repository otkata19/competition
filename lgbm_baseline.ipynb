{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('py38': conda)",
      "metadata": {
        "interpreter": {
          "hash": "168065e78b87d8dffb691e13d6c7c849aa7e5c74da65b9131a558403d419cad9"
        }
      }
    },
    "colab": {
      "name": "lgbm_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "30f8SFD_Z3fs"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otkata19/competition/blob/main/lgbm_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePFOk520Z3fg"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfEoy_FiZ3fj"
      },
      "source": [
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nb_CNeyZ3fk"
      },
      "source": [
        "%matplotlib inline\n",
        "font = {'family':'IPAexGothic'}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTyrYVXSZ3fl"
      },
      "source": [
        "## Load Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzhext0ThkDa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whYyXueu78LK"
      },
      "source": [
        "cd /content/drive/My Drive/Nishika/Narou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zhMgQeHiCU1",
        "collapsed": true
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueJRl1OgkTyk"
      },
      "source": [
        "df_exp = pd.read_csv(\"sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4B_CWPEZ3fl"
      },
      "source": [
        "fparh = Path('./')\n",
        "\n",
        "train_fname = 'train.csv'\n",
        "test_fname = 'test.csv'\n",
        "sub_fname = 'sample_submission.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "J7LW2M9tZ3fl"
      },
      "source": [
        "df_train = pd.read_csv(fparh / train_fname)\n",
        "df_test = pd.read_csv(fparh / test_fname)\n",
        "submission = pd.read_csv(fparh / sub_fname)\n",
        "\n",
        "print('df_train shape :', df_train.shape)\n",
        "print('df_test shape :', df_test.shape)\n",
        "print('submission shape :', submission.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-HIzXp8Z3fm",
        "collapsed": true
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8rgAFTrZ3fm",
        "collapsed": true
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y_IXFILZ3fn"
      },
      "source": [
        "## Distribution of Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTdXsaISZ3fn"
      },
      "source": [
        "df_train['fav_novel_cnt_bin'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MjHSgvLZ3fo"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 9))\n",
        "plt.hist(df_train['fav_novel_cnt_bin'], bins=5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAxbcwYeZ3fo"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXK-eLqOZ3fp"
      },
      "source": [
        "def fit(tr_x, tr_y, va_x, va_y, tr_w=None, va_w=None):\n",
        "    \"\"\"\n",
        "    model training\n",
        "  \n",
        "    Parameters\n",
        "    ----------\n",
        "    tr_x: pd.DataFrame\n",
        "    tr_y: pd.DataFrame\n",
        "    va_x: pd.DataFrame\n",
        "    va_y: pd.DataFrame\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    model:\n",
        "        - 学習済みモデル\n",
        "    va_pred: \n",
        "        - 検証データの予測結果\n",
        "    \"\"\" \n",
        "    # パラメータの設定\n",
        "    params = {\n",
        "        'objective': 'multiclass',  \n",
        "        'boosting_type': 'gbdt',\n",
        "        'metrics': 'multi_logloss',\n",
        "        'num_class': 5,\n",
        "        'seed': 777,\n",
        "        'learning_rate': 0.01,\n",
        "        'n_jobs': -1,\n",
        "        'verbose': -1\n",
        "        }\n",
        "\n",
        "    # 学習セットを作成\n",
        "    lgb_train = lgb.Dataset(tr_x, tr_y)\n",
        "    lgb_eval = lgb.Dataset(va_x, va_y, reference=lgb_train)\n",
        "\n",
        "    # モデルの学習\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_set=lgb_train, # トレーニングデータの指定\n",
        "        valid_sets=[lgb_train, lgb_eval],\n",
        "        valid_names=['train', 'valid'],\n",
        "        num_boost_round=1000,\n",
        "        early_stopping_rounds = 100,\n",
        "        verbose_eval = 20\n",
        "        )\n",
        "    \n",
        "    # 検証データの予測確率\n",
        "    va_pred = model.predict(va_x)\n",
        "\n",
        "    return model, va_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ0h1X3XZ3fp"
      },
      "source": [
        "def scoring(y_true, y_prob):\n",
        "    \"\"\"Multi-class logloss\"\"\"\n",
        "    return log_loss(y_true, y_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdhiyVGuq762",
        "collapsed": true
      },
      "source": [
        "df_train['userid']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "anJbdFOF8Vcy"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "g0TBYa4i8f2L"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CT3p-o2E74DW"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "class BertSequenceVectorizer:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = transformers.T5Tokenizer.from_pretrained(self.model_name)\n",
        "        self.tokenizer.do_lower_case = True \n",
        "        self.bert_model = transformers.RobertaModel.from_pretrained(self.model_name)\n",
        "        self.bert_model = self.bert_model.to(self.device)\n",
        "        self.max_len = 128\n",
        "\n",
        "    def vectorize(self, sentence : str) -> np.array:\n",
        "        inp = self.tokenizer.encode(sentence)\n",
        "        len_inp = len(inp)\n",
        "\n",
        "        if len_inp >= self.max_len:\n",
        "            inputs = inp[:self.max_len]\n",
        "            masks = [1] * self.max_len\n",
        "        else:\n",
        "            inputs = inp + [0] * (self.max_len - len_inp)\n",
        "            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n",
        "\n",
        "        inputs_tensor = torch.tensor([inputs], dtype=torch.long).to(self.device)\n",
        "        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n",
        "\n",
        "        bert_out = self.bert_model(inputs_tensor, masks_tensor)\n",
        "        seq_out, pooled_out = bert_out['last_hidden_state'], bert_out['pooler_output']\n",
        "\n",
        "        if torch.cuda.is_available():    \n",
        "            return seq_out[0][0].cpu().detach().numpy()\n",
        "        else:\n",
        "            return seq_out[0][0].detach().numpy()\n",
        "\n",
        "DATA_DIR = Path('./')\n",
        "\n",
        "train = pd.read_csv(DATA_DIR / 'train.csv')\n",
        "test = pd.read_csv(DATA_DIR / 'test.csv')\n",
        "\n",
        "BSV = BertSequenceVectorizer('rinna/japanese-roberta-base')\n",
        "\n",
        "for col in ['title', 'story', 'keyword']:\n",
        "    print('##########' + col + '##########')\n",
        "    train[col] = train[col].fillna('NaN')\n",
        "    test[col] = test[col].fillna('NaN')\n",
        "    np.save(f'train_{col}_roberta', np.stack(train[col].progress_apply(lambda x: BSV.vectorize(x))))\n",
        "    np.save(f'test_{col}_roberta', np.stack(test[col].progress_apply(lambda x: BSV.vectorize(x))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQ-FtqdSmlA"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FxYOiD9pR2zk"
      },
      "source": [
        "train_story = np.load('train_story_roberta.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH7izbOmZ3fq"
      },
      "source": [
        "# 値が全て同じカラムとobject型のカラムは使用しない\n",
        "drop_lst = ['end', 'isstop']\n",
        "object_lst = ['ncode', 'general_firstup', 'title', 'story', 'keyword', 'writer']\n",
        "\n",
        "df_train_numeric = df_train.drop(drop_lst, axis=1)\n",
        "df_train_numeric = df_train_numeric.drop(object_lst, axis=1)\n",
        "\n",
        "df_test_numeric = df_test.drop(drop_lst, axis=1)\n",
        "df_test_numeric = df_test_numeric.drop(object_lst, axis=1)\n",
        "\n",
        "df_train_numeric.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM4ZdmcDZ3fq"
      },
      "source": [
        "# 説明変数,目的変数を分割\n",
        "X = df_train_numeric.drop('fav_novel_cnt_bin', axis=1)\n",
        "y = df_train_numeric['fav_novel_cnt_bin']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAcpeecgcTpL",
        "collapsed": true
      },
      "source": [
        "df_pred = pd.DataFrame(index=X.index, columns=['proba_0', 'proba_1', 'proba_2',\t'proba_3', 'proba_4'])\n",
        "df_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIgUfIMxZ3fq"
      },
      "source": [
        "#@title\n",
        "models = []\n",
        "df_pred = pd.DataFrame(index=X.index, columns=['proba_0', 'proba_1', 'proba_2',\t'proba_3', 'proba_4'])\n",
        "\n",
        "# トレーニングデータ,テストデータの分割\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(train_story, y),1):\n",
        "    print('---CV{i}---')\n",
        "    # X_train, y_train = X.loc[train_index], y.loc[train_index]\n",
        "    # X_valid, y_valid = X.loc[valid_index], y.loc[valid_index]\n",
        "    print(len(train_story[train_index]), len(y.loc[train_index]))\n",
        "    X_train, y_train = train_story[train_index], y.loc[train_index]\n",
        "    X_valid, y_valid = train_story[valid_index], y.loc[valid_index]\n",
        "    # モデルの学習\n",
        "    model, va_pred = fit(X_train, y_train, X_valid, y_valid) \n",
        "    # モデルの格納\n",
        "    models.append(model)\n",
        "    # 検証データの予測結果を格納\n",
        "    df_pred.loc[valid_index] = va_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhuYCXEYZNDY"
      },
      "source": [
        "models = []\n",
        "df_pred = pd.DataFrame(index=X.index, columns=['proba_0', 'proba_1', 'proba_2',\t'proba_3', 'proba_4'])\n",
        "\n",
        "# トレーニングデータ,テストデータの分割\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "for train_index, valid_index in skf.split(X, y):\n",
        "    print('---CV{i}---')\n",
        "    X_train, y_train = X.loc[train_index], y.loc[train_index]\n",
        "    X_valid, y_valid = X.loc[valid_index], y.loc[valid_index]\n",
        "    # モデルの学習\n",
        "    model, va_pred = fit(X_train, y_train, X_valid, y_valid) \n",
        "    # モデルの格納\n",
        "    models.append(model)\n",
        "    # 検証データの予測結果を格納\n",
        "    df_pred.loc[valid_index] = va_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kduT2grhP4DR"
      },
      "source": [
        "models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVOdGaXFQOvf"
      },
      "source": [
        "# モデルの保存\n",
        "import pickle\n",
        "\n",
        "# カレントディレクトリへモデルを保存\n",
        "file = 'trained_model.pkl'\n",
        "pickle.dump(models, open(file, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OqjaOtHQhRa"
      },
      "source": [
        "# モデルの削除\n",
        "del models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-pMC5FCQXwh"
      },
      "source": [
        "models = pickle.load(open('trained_model.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jCGgBemSXJu"
      },
      "source": [
        "df_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM1LKgIPZ3fr"
      },
      "source": [
        "# CVスコア\n",
        "scoring(df_train['fav_novel_cnt_bin'], df_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZSYd9d8Z3fr"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjZ8avBCZ3fr"
      },
      "source": [
        "def predict(models, x):\n",
        "    \"\"\"\n",
        "    prediction\n",
        "  \n",
        "    Parameters\n",
        "    ----------\n",
        "    models: list\n",
        "        - trained model\n",
        "    x: pd.DataFrame\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    result: pd.DataFrame\n",
        "    \"\"\" \n",
        "    result = pd.DataFrame(0, index=x.index, columns=['proba_0',\t'proba_1', 'proba_2', 'proba_3', 'proba_4'])\n",
        "    for model in models:\n",
        "        pred_prob = model.predict(x, num_iteration=model.best_iteration)\n",
        "        lgb.plot_importance(model, figsize=(12,8), max_num_features=50, importance_type='gain')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        df_pred = pd.DataFrame(pred_prob, index=x.index, columns=['proba_0', 'proba_1', 'proba_2', 'proba_3', 'proba_4'])\n",
        "        result += df_pred\n",
        "    result = result / 5\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mR7CvxNQ8TK"
      },
      "source": [
        "df_test_numeric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRohoVTSRBqi"
      },
      "source": [
        "result = predict(models, df_test_numeric)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30f8SFD_Z3fs"
      },
      "source": [
        "## Create Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdAtMhV_Z3fs"
      },
      "source": [
        "output_fpath = Path('./')\n",
        "submission.iloc[:, 1:] = result\n",
        "submission.to_csv(output_fpath / 'submission.csv', header=True, index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ojah6fdRzT_"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSxXTDvnR40D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}